---
title: "hbc_scRNA-seq training - integration"
output: html_document
---

# Single-cell RNA-seq clustering analysis: Integration

```{r setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 12, fig.height = 7)
```

### Learning Objectives:

-   Perform integration of cells across conditions to identify cells that are similar to each other
-   Describe complex integration tasks and alternative tools for integration

***Goals:***

-   *To **align same cell types** across conditions.*

***Challenges:***

-   ***Aligning cells of similar cell types** so that we do not have clustering downstream due to differences between samples, conditions, modalities, or batches*

***Recommendations:***

-   *Go through the analysis without integration first to determine whether integration is necessary*

------------------------------------------------------------------------

## To integrate or not no integrate?

Clustering without integration first to decide whether or not to perform alignment. For this workshop, in the normalization step, normalization were performed on both conditions together in a Seurat object `seurat_phase`, we can create an UMAP to see if there is a sample-specific clustering:

```{r run UMAP}
# seurat_phase object was generated in the 
# For this object we have already run PCA
# Run UMAP
seurat_phase <- RunUMAP(seurat_phase,
dims = 1:40,reduction = "pca")
# Plot UMAP
DimPlot(seurat_phase)
```

Condition-specific clustering of the cells indicates that we need to integrate the cells across conditions to ensure that cells of the same type cluster together.

This will enable more interpretable results downstream(i.e. DE analysis, ligand-receptor analysis, differential abundance analysis ...)

## Integrate or align samples across conditions using shared highly variable genes

## Integrating using CCA(canonical correlation analysis) in the Seurat package

*Steps applied:* 1. Perform canonical correlation analysis CCA is a form of PCA, but it identifies the greatest sources of variation in the data and only kept if it is shared or conserved across the conditions/samples(using the 3000 most variant genes from each sample)

2.  Identify anchors or mutual nearest neighbors(MNN) across datasets (sometimes incorrect anchors are identified)

3.  Filter anchors

4.  Integrate the conditions

Use anchors and corresponding scores to transform the cell expression values, allowing for the integration of the conditions/datasets (different samples, conditions, datasets, modalities)

> NOTE: Transformation of each cell uses a weighted average of the two cells of each anchor across anchors of the datasets. Weights determined by cell similarity score (distance between cell and k nearest anchors) and anchor scores, so cells in the same neighborhood should have similar correction values.

## Perform the integration across conditions

1.  Select the most variable features to use for integration

```{r}
# specify using all of the 3000 most variable genes identified by SCTransform by set nfeatures
integ_features <- SelectIntegrationFeatures(object.list = split_seurat, 
                                            nfeatures = 3000) 
```

2.  Prepare the SCTransform object for integration.

```{r}
split_seurat <- PrepSCTIntegration(object.list = split_seurat, 
                                   anchor.features = integ_features)
```

3.  Perform CCA, find the best buddies or anchors and filter incorrect anchors.

```{r perfrom CCA}
# Find best buddies - can take a while to run
integ_anchors <- FindIntegrationAnchors(object.list = split_seurat, 
                                        normalization.method = "SCT", 
                                        anchor.features = integ_features)
```

4.  Integrate across conditions

```{r}
# Integrate across conditions
seurat_integrated <- IntegrateData(anchorset = integ_anchors, 
                                   normalization.method = "SCT")
```

### UMAP visualization after integration

```{r visualize with PCA}
# Run PCA
seurat_integrated <- RunPCA(object = seurat_integrated)

# Plot PCA
PCAPlot(seurat_integrated,
        split.by = "sample")  

```

```{r visualize with UMAP}

# Set seed to avoid the creation of a slightly different umap each time
# usually set seed at the beginning of the script
set.seed(123456)

# Run UMAP
seurat_integrated <- RunUMAP(seurat_integrated, 
                             dims = 1:40,
			     reduction = "pca")

# Plot UMAP                             
DimPlot(seurat_integrated)                             
```

*Side-by-side comparison of clusters* Split the plotting between conditions for easier comparison

```{r}
# Plot UMAP split by sample
DimPlot(seurat_integrated,
        split.by = "sample")  
```

```{r}
# Save integrated seurat object
saveRDS(seurat_integrated, "results/integrated_seurat.rds")
```

## Complex Integration Tasks

The "complexity" of integrating a dataset may relate to the number of samples (perhaps generated using different protocols) but also to the biological question the study seeks to address (e.g. comparing cell types across tissues, species...). In these contexts, **you may need to integrate across multiple confounding factors before you can start exploring the biology of your system.**

In these **more complex scenarios**, you want to select a data integration approach that successfully balances out the following challenges:

-   Correcting for inter-sample variability due to source samples from different donors
-   Correcting for variability across protocols/technologies (10X, SMART-Seq2, inDrop...; single-cell vs. single nucleus; variable number of input cells and sequencing depth; different sample preparation steps...)
-   Identifying consistent cell types across different tissues (peripheral blood, bone marrow, lung...) and/or different locations (e.g. areas of the brain)
-   Keeping apart cell subtypes (or even cell states) that show similar transcriptomes (CD4 naive vs. memory, NK vs NKT)
-   Keeping apart cell subtypes that are unique to a tissue/condition
-   Conserving the developmental trajectory, if applicable

Not all tools may perform as well on every task, and complex datasets may require testing several data integration approaches. You might want to analyze independently each of the batches you consider to integrate across, in order to define cell identities at this level before integrating and checking that the initially annotated cell types are mixed as expected.

## Integration with Harmony

`Harmony` is a possible alternative to the `Seurat` integratation workflow. Compared to other algorithms, `Harmony` notably presents the following advantages ([Korsunsky et al. 2019](https://www.nature.com/articles/s41592-019-0619-0), [Tran et al. 2020](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1850-9)):

1.  Possibility to integrate data across several variables (e.g., by experimental batch and by condition)
2.  Significant gain in speed and lower memory requirements for integration of large datasets
3.  Interoperability with the `Seurat` workflow

Instead of using CCA, `Harmony` applies a transformation to the principal component (PCs) values, using all available PCs, e.g. as pre-computed within the `Seurat` workflow.

In this space of transformed PCs, `Harmony` uses k-means clustering to delineate clusters, seeking to define clusters with maximum "diversity". The diversity of each cluster reflects whether it contains balanced amounts of cells from each of the batches (donor, condition, tissue, technolgy...) we seek to integrate on, as should be observed in a well-integrated dataset.

After defining diverse clusters, `Harmony` determines how much a cell's batch identity impacts on its PC coordinates, and applies a correction to "shift" the cell towards the centroid of the cluster it belongs to.

Cells are projected again using these corrected PCs, and the process is repeated iteratively until convergence. ![Harmony](figures/harmony_overview.jpeg)


### Implementing Harmony within the Seurat workflow

To perform integration, `Harmony` takes as input a *merged* Seurat object, containing data that has been appropriately normalized (i.e. here, normalized using `SCTransform`) and for which highly variable features and PCs are defined.

There are 2 ways to reach that point:
1. Merge the *raw* Seurat objects for all samples to integrate; then perform normalization, variable feature selection and PC calculation on this merged object (workflow recommended by `Harmony` developers)

assuming `raw_seurat_list` is a list of N samples containing raw data that have only undergone QC filtering, we would thus run the following code:

```{r merge before normalization/feature selection and PCA}
# Merge raw samples
merged_seurat <- merge(x = raw_seurat_list[[1]],
		       y = raw_seurat_list[2:length(raw_seurat_list)],
		       merge.data = TRUE)

# Perform log-normalization and feature selection, as well as SCT normalization on global object
merged_seurat <- merged_seurat %>%
    NormalizeData() %>%
    FindVariableFeatures(selection.method = "vst", nfeatures = 2000) %>% 
    ScaleData() %>%
    SCTransform(vars.to.regress = c("mitoRatio"))

# Calculate PCs using variable features determined by SCTransform (3000 by default)
merged_seurat <- RunPCA(merged_seurat, assay = "SCT", npcs = 50)
```
2. Perform (SCT) normalization independently on each sample and find integration features across samples using `Seurat`; then merge these *normalized* Seurat objects, set variable features manually to integration features, and finally calculate PCs on this merged object (workflow best reflecting recommendations for application of `SCTransform`)

Assuming `norm_seurat_list` is a list of N samples similar to our `split_seurat` object, i.e. containing data that have been normalized as demonstrated in the previous lecture on SCT normalization, we would thus run the following code:

```{r merge on normalized samples}
# Find most variable features across samples to integrate
integ_features <- SelectIntegrationFeatures(object.list = norm_seurat_list, nfeatures = 3000) 

# Merge normalized samples
merged_seurat <- merge(x = norm_seurat_list[[1]],
		       y = norm_seurat_list[2:length(raw_seurat_list)],
		       merge.data = TRUE)
DefaultAssay(merged_seurat) <- "SCT"

# Manually set variable features of merged Seurat object
VariableFeatures(merged_seurat) <- integ_features

# Calculate PCs using manually set variable features
merged_seurat <- RunPCA(merged_seurat, assay = "SCT", npcs = 50)
```

There is active discussion regarding which of those 2 approaches to use. Check GitHub forums to make your choice and for updates.

Regardless, we now have a merged Seurat object containing normallized data for all the samples we need to integrate, as well as defined variable features and PCs.

Before running `Harmony`, make sure that the metadata of the Seurat object contains one(or several) variable(s) describing the factors we want to integrate on(e.g., `sample_id` and `experiment_date`).

```{r run Harmony}
harmonized_seurat <- RunHarmony(merged_seurat, 
				group.by.vars = c("sample_id", "experiment_date"), 
				reduction = "pca", assay.use = "SCT", reduction.save = "harmony")
```
The line of code above adds a new reduction of 50 "harmony components" (~ corrected PCs) to our Seurat object, stored in `harmonized_seurat@reductions$harmony`.

Generate a UMAP derived from these harmony embeddings instead of PCs:
```{r}
harmonized_seurat <- RunUMAP(harmonized_seurat, reduction = "harmony", assay = "SCT", dims = 1:40)
```
Finally, when running the clustering analysis later on, we will also need to set the reduction to use as "harmony" (instead of "pca" by default).

```{r}
harmonized_seurat <- FindNeighbors(object = harmonized_seurat, reduction = "harmony")
harmonized_seurat <- FindClusters(harmonized_seurat, resolution = c(0.2, 0.4, 0.6, 0.8, 1.0, 1.2))
```


The rest of the Seurat workflow and downstream analyses after integration using Harmony can then proceed without further amendments.

